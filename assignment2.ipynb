{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, ReLU, Conv2d, Linear, MaxPool2d, LogSoftmax\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {\n",
    "    'data_augmentation': False,\n",
    "    'batch_normalization': False,\n",
    "    'filters': 32, # no. of filters in first layer\n",
    "    'filter_org': 'same', # 'half', 'double'\n",
    "    'dropout': 0,\n",
    "    'activation': 'relu',\n",
    "    'train_data_dir': \"./data/val\",\n",
    "    'test_data_dir': \"./data/val\",\n",
    "    'batch_size': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    0:'Amphibia',\n",
    "    1:'Animalia',\n",
    "    2:'Arachnida',\n",
    "    3:'Aves',\n",
    "    4:'Fungi',\n",
    "    5:'Insecta',\n",
    "    6:'Mammalia',\n",
    "    7:'Mollusca',\n",
    "    8:'Plantae',\n",
    "    9:'Reptilia'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_labels(param):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  # Normalize pixel values\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=param['train_data_dir'], transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=param['batch_size'], shuffle=True)\n",
    "    for images, labels in dataloader:\n",
    "        # process_image_batch(images)\n",
    "        # process_label_batch(labels)\n",
    "  \n",
    "        print(f\"Image batch shape: {images.shape}\")\n",
    "        print(f\"Sample label: {labels}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([5, 6, 5, 8, 7, 8, 3, 4, 5, 7, 4, 2, 5, 6, 6, 6, 3, 3, 4, 3, 8, 4, 8, 0,\n",
      "        6, 4, 3, 4, 7, 2, 2, 5])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([5, 7, 6, 2, 7, 6, 0, 7, 1, 8, 9, 0, 7, 2, 0, 9, 2, 6, 9, 8, 5, 3, 6, 2,\n",
      "        8, 1, 9, 9, 6, 1, 2, 7])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([1, 1, 6, 3, 8, 7, 1, 4, 4, 2, 3, 6, 3, 0, 9, 3, 4, 2, 7, 2, 5, 0, 8, 5,\n",
      "        5, 4, 5, 6, 9, 3, 7, 5])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([0, 6, 1, 8, 2, 4, 8, 1, 5, 7, 8, 0, 1, 3, 7, 5, 9, 1, 3, 8, 1, 9, 3, 1,\n",
      "        2, 8, 3, 7, 2, 9, 5, 5])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([5, 1, 9, 5, 9, 8, 2, 0, 4, 7, 9, 5, 3, 2, 7, 3, 9, 3, 6, 2, 0, 1, 1, 2,\n",
      "        4, 2, 5, 1, 8, 6, 8, 1])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([1, 5, 4, 9, 4, 4, 4, 0, 2, 0, 6, 8, 5, 9, 8, 7, 0, 4, 4, 9, 8, 8, 5, 2,\n",
      "        0, 2, 4, 6, 0, 4, 2, 1])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([6, 9, 6, 5, 3, 1, 5, 9, 2, 6, 0, 1, 2, 6, 0, 8, 5, 0, 0, 8, 1, 5, 5, 2,\n",
      "        9, 7, 6, 2, 8, 4, 7, 8])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([7, 5, 3, 8, 5, 8, 2, 7, 7, 9, 7, 9, 7, 3, 2, 0, 9, 3, 6, 2, 0, 2, 7, 2,\n",
      "        7, 5, 3, 5, 0, 2, 4, 8])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([2, 4, 7, 0, 7, 0, 1, 8, 7, 3, 5, 2, 9, 9, 1, 9, 5, 1, 8, 9, 8, 8, 6, 5,\n",
      "        3, 5, 9, 5, 3, 7, 5, 5])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([2, 3, 9, 6, 0, 7, 6, 4, 6, 9, 3, 8, 0, 7, 8, 7, 5, 4, 6, 3, 7, 5, 0, 9,\n",
      "        4, 8, 1, 0, 1, 1, 7, 7])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([6, 7, 7, 8, 4, 5, 6, 8, 6, 7, 0, 1, 2, 6, 9, 1, 0, 7, 1, 9, 8, 7, 1, 2,\n",
      "        0, 8, 9, 0, 5, 2, 3, 2])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([3, 5, 5, 6, 3, 9, 3, 4, 0, 3, 0, 6, 8, 7, 7, 4, 1, 1, 8, 8, 5, 4, 7, 6,\n",
      "        1, 1, 1, 0, 4, 0, 8, 2])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([9, 4, 7, 0, 3, 0, 4, 9, 3, 6, 2, 1, 0, 8, 6, 6, 1, 0, 7, 5, 5, 4, 4, 3,\n",
      "        8, 7, 8, 8, 3, 9, 4, 3])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([7, 1, 2, 8, 8, 0, 3, 6, 4, 8, 4, 3, 7, 6, 1, 4, 2, 9, 6, 1, 7, 5, 4, 9,\n",
      "        8, 4, 8, 5, 6, 0, 6, 3])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([2, 6, 4, 1, 3, 9, 1, 4, 9, 8, 6, 1, 2, 0, 9, 8, 4, 0, 8, 9, 2, 4, 6, 9,\n",
      "        1, 4, 2, 4, 2, 5, 6, 1])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([2, 7, 8, 5, 8, 9, 2, 8, 9, 0, 6, 6, 9, 6, 7, 4, 4, 8, 6, 6, 6, 6, 7, 7,\n",
      "        8, 1, 2, 2, 3, 4, 7, 4])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([9, 3, 2, 1, 1, 4, 6, 4, 5, 3, 3, 4, 5, 1, 8, 3, 2, 9, 1, 1, 2, 0, 1, 6,\n",
      "        9, 1, 6, 3, 4, 6, 2, 8])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([2, 6, 6, 9, 8, 4, 0, 2, 2, 1, 8, 3, 9, 7, 4, 7, 3, 9, 7, 1, 5, 8, 6, 1,\n",
      "        0, 6, 5, 5, 2, 3, 8, 5])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([1, 5, 6, 3, 9, 7, 5, 0, 0, 7, 9, 6, 9, 9, 1, 0, 3, 0, 2, 1, 3, 6, 1, 5,\n",
      "        8, 7, 4, 5, 5, 0, 1, 8])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([4, 5, 4, 4, 5, 5, 0, 5, 5, 2, 0, 8, 8, 7, 7, 6, 9, 4, 6, 0, 5, 7, 9, 8,\n",
      "        6, 6, 7, 0, 5, 9, 7, 2])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([9, 3, 0, 9, 0, 3, 8, 0, 8, 7, 4, 1, 8, 9, 3, 1, 9, 4, 0, 2, 5, 2, 6, 5,\n",
      "        1, 5, 5, 0, 1, 8, 7, 6])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([8, 1, 1, 7, 3, 3, 4, 8, 3, 0, 0, 8, 2, 4, 3, 5, 9, 7, 8, 3, 9, 4, 8, 0,\n",
      "        4, 9, 1, 6, 7, 8, 3, 9])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample label: tensor([0, 7, 1, 7, 2, 6, 7, 9, 3, 5, 6, 1, 0, 1, 9, 3, 0, 3, 0, 1, 2, 7, 0, 2,\n",
      "        8, 3, 3, 1, 7, 1, 0, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprint_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPARAMETERS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36mprint_labels\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m      8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# process_image_batch(images)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# process_label_batch(labels)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/datasets/folder.py:231\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/functional.py:467\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    465\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/PIL/Image.py:2200\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2193\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2194\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2195\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2196\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2197\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2198\u001b[0m         )\n\u001b[0;32m-> 2200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print_labels(PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(Module):\n",
    "#     def __self__(self, param):\n",
    "#         self.data_augmentation = param['data_augmentation']\n",
    "#         self.batch_normalization = param['batch_normalization']\n",
    "#         self.filters = param['filters']\n",
    "#         self.filter_org = param['filter_org']\n",
    "#         self.dropout = param['dropout']\n",
    "#         self.activation = param['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "class CNN:\n",
    "    def __self__(self, param):\n",
    "        super().__init__()\n",
    "        self.data_augmentation = param['data_augmentation']\n",
    "        self.batch_normalization = param['batch_normalization']\n",
    "        self.dropout = param['dropout']\n",
    "        self.activation = param['activation']\n",
    "        self.filters = self.filter_logic(param['filters'], param['filter_org'])\n",
    "\n",
    "        self.conv1 = Conv2d(kernel_size=(3,3), in_channels=3, out_channels=self.filters[0])\n",
    "        self.act1 = ReLU()\n",
    "        self.pool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv2 = Conv2d(kernel_size=(3,3), in_channels=self.filters[0], out_channels=self.filters[1])\n",
    "        self.act2 = ReLU()\n",
    "        self.pool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv3 = Conv2d(kernel_size=(3,3), in_channels=self.filters[1], out_channels=self.filters[2])\n",
    "        self.act3 = ReLU()\n",
    "        self.pool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv4 = Conv2d(kernel_size=(3,3), in_channels=self.filters[2], out_channels=self.filters[3])\n",
    "        self.act4 = ReLU()\n",
    "        self.pool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv5 = Conv2d(kernel_size=(3,3), in_channels=self.filters[3], out_channels=self.filters[4])\n",
    "        self.act5 = ReLU()\n",
    "        self.pool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.fc1 = Linear(in_features=self.filters[4]*prev_dim, out_features=500)  # How to calculate dimension of filters at previous level\n",
    "        self.act6 = ReLU()\n",
    "        \n",
    "        self.out = Linear(in_features=500, out_features=10)\n",
    "        self.act7 = LogSoftmax(dim=1)\n",
    "\n",
    "    \n",
    "    def filter_logic(self, filter, org):\n",
    "        level = []\n",
    "        org = org.lower()\n",
    "        if org == 'same':\n",
    "            level = [filter for i in range(5)]\n",
    "        elif org == 'double':\n",
    "            level = [filter*pow(2,i) for i in range(5)]\n",
    "        elif org == 'half':\n",
    "            level = [max(filter//pow(2,i),1) for i in range(5)]\n",
    "        return level\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
