{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, ReLU, Conv2d, Linear, MaxPool2d, LogSoftmax, NLLLoss, Dropout, BatchNorm2d, LeakyReLU, GELU, SELU, Mish\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import flatten, float, no_grad\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import wandb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {\n",
    "    'data_augmentation': False,\n",
    "    'batch_normalization': False,\n",
    "    'filters': 32, # no. of filters in first layer\n",
    "    'filter_org': 'same', # 'half', 'double'\n",
    "    'dropout': 0,\n",
    "    'activation': 'relu',\n",
    "    'train_data_dir': \"./data/train\",\n",
    "    'test_data_dir': \"./data/val\",\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 3,\n",
    "    'dim': 256,\n",
    "    'conv_kernel_size': 3,\n",
    "    'dense_neurons': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    0:'Amphibia',\n",
    "    1:'Animalia',\n",
    "    2:'Arachnida',\n",
    "    3:'Aves',\n",
    "    4:'Fungi',\n",
    "    5:'Insecta',\n",
    "    6:'Mammalia',\n",
    "    7:'Mollusca',\n",
    "    8:'Plantae',\n",
    "    9:'Reptilia'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(param, type):\n",
    "    if(type.lower() == 'train'):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.3),\n",
    "            transforms.RandomRotation(degrees=12),\n",
    "            transforms.Resize((param['dim'],param['dim'])),\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n",
    "        ])\n",
    "\n",
    "        tdataset = datasets.ImageFolder(root=param['train_data_dir'], transform=transform)\n",
    "        total = len(tdataset)\n",
    "        train_sample = math.ceil(total*(0.8))\n",
    "        val_sample = total-train_sample\n",
    "        # print(total, train_sample, val_sample)\n",
    "        train_dataset, validation_dataset = torch.utils.data.random_split(tdataset, [train_sample, val_sample])\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=param['batch_size'], shuffle=True)\n",
    "        validation_dataloader = DataLoader(validation_dataset, batch_size=param['batch_size'], shuffle=False)\n",
    "        return train_dataloader, validation_dataloader\n",
    "    \n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((param['dim'],param['dim'])),\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n",
    "        ])\n",
    "        test_dataset = datasets.ImageFolder(root=param['test_data_dir'], transform=transform)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=param['batch_size'])\n",
    "        return test_dataloader\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr, val = get_data(PARAMETERS, 'train')\n",
    "# for (img,label) in val:\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self, param):\n",
    "        super(CNN, self).__init__()\n",
    "        self.param=param\n",
    "        self.data_augmentation = param['data_augmentation']\n",
    "        self.dropout = param['dropout']\n",
    "        self.act = self.getActivation(param['activation'])\n",
    "        self.filters = self.filter_logic(param['filters'], param['filter_org'])\n",
    "        self.conv_ks = param['conv_kernel_size']\n",
    "        self.dim = param['dim']\n",
    "        self.bn = param['batch_normalization']\n",
    "        self.dense_neurons = param['dense_neurons']\n",
    "\n",
    "\n",
    "        curr_dim = self.dim\n",
    "        self.conv1 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=3, out_channels=self.filters[0])\n",
    "        curr_dim -= (self.conv_ks-1)\n",
    "        self.act1 = self.act\n",
    "        if(self.bn): self.bn1 = BatchNorm2d(self.filters[0])\n",
    "        self.pool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        curr_dim //= 2\n",
    "        self.dropout1 = Dropout(p=self.dropout)\n",
    "\n",
    "        self.conv2 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[0], out_channels=self.filters[1])\n",
    "        curr_dim -= (self.conv_ks-1)\n",
    "        self.act2 = self.act\n",
    "        if(self.bn): self.bn2 = BatchNorm2d(self.filters[1])\n",
    "        self.pool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        curr_dim //= 2\n",
    "        self.dropout2 = Dropout(p=self.dropout)\n",
    "\n",
    "        self.conv3 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[1], out_channels=self.filters[2])\n",
    "        curr_dim -= (self.conv_ks-1)\n",
    "        self.act3 = self.act\n",
    "        if(self.bn): self.bn3 = BatchNorm2d(self.filters[2])\n",
    "        self.pool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        curr_dim //= 2\n",
    "        self.dropout3 = Dropout(p=self.dropout)\n",
    "\n",
    "        self.conv4 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[2], out_channels=self.filters[3])\n",
    "        curr_dim -= (self.conv_ks-1)\n",
    "        self.act4 = self.act\n",
    "        if(self.bn): self.bn4 = BatchNorm2d(self.filters[3])\n",
    "        self.pool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        curr_dim //= 2\n",
    "        self.dropout4 = Dropout(p=self.dropout)\n",
    "\n",
    "        self.conv5 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[3], out_channels=self.filters[4])\n",
    "        curr_dim -= (self.conv_ks-1)\n",
    "        self.act5 = self.act\n",
    "        if(self.bn): self.bn5 = BatchNorm2d(self.filters[4])\n",
    "        self.pool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        curr_dim //= 2\n",
    "        self.dropout5 = Dropout(p=self.dropout)\n",
    "\n",
    "        ########## Comment out below line later ############    \n",
    "        self.dense_neurons = curr_dim * curr_dim * self.filters[4]\n",
    "\n",
    "        self.fc1 = Linear(in_features=(curr_dim * curr_dim * self.filters[4]), out_features=self.dense_neurons)  # How to calculate dimension of filters at previous level\n",
    "        self.act6 = self.act\n",
    "        self.dropout6 = Dropout(p=0.5)\n",
    "        \n",
    "        self.out = Linear(in_features=self.dense_neurons, out_features=10)\n",
    "        self.act7 = LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def getActivation(self, act):\n",
    "        act = act.lower()\n",
    "        if(act == 'relu'):\n",
    "            return ReLU()\n",
    "        elif(act == 'leakyrelu'):\n",
    "            return LeakyReLU()\n",
    "        elif(act == 'gelu'):\n",
    "            return GELU()\n",
    "        elif(act == 'selu'):\n",
    "            return SELU()\n",
    "        elif(act == 'mish'):\n",
    "            return Mish()\n",
    "    \n",
    "\n",
    "    def filter_logic(self, filter, org):\n",
    "        level = []\n",
    "        org = org.lower()\n",
    "        if org == 'same':\n",
    "            level = [filter for i in range(5)]\n",
    "        elif org == 'double':\n",
    "            level = [filter*pow(2,i) for i in range(5)]\n",
    "        elif org == 'half':\n",
    "            level = [max(filter//pow(2,i),1) for i in range(5)]\n",
    "        return level\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, r):\n",
    "\n",
    "        r=self.conv1(r)\n",
    "        r=self.act1(r)\n",
    "        if(self.bn): r=self.bn1(r)\n",
    "        r=self.pool1(r)\n",
    "        r=self.dropout1(r)\n",
    "\n",
    "        r=self.conv2(r)\n",
    "        r=self.act2(r)\n",
    "        if(self.bn): r=self.bn2(r)\n",
    "        r=self.pool2(r)\n",
    "        r=self.dropout2(r)\n",
    "\n",
    "        r=self.conv3(r)\n",
    "        r=self.act3(r)\n",
    "        if(self.bn): r=self.bn3(r)\n",
    "        r=self.pool3(r)\n",
    "        r=self.dropout3(r)\n",
    "\n",
    "        r=self.conv4(r)\n",
    "        r=self.act4(r)\n",
    "        if(self.bn): r=self.bn4(r)\n",
    "        r=self.pool4(r)\n",
    "        r=self.dropout4(r)\n",
    "\n",
    "        r=self.conv5(r)\n",
    "        r=self.act5(r)\n",
    "        if(self.bn): r=self.bn5(r)\n",
    "        r=self.pool5(r)\n",
    "        r=self.dropout5(r)\n",
    "\n",
    "        r=flatten(r,1)\n",
    "        r=self.fc1(r)\n",
    "        r=self.act6(r)\n",
    "        r=self.dropout6(r)\n",
    "        \n",
    "        r=self.out(r)\n",
    "        output=self.act7(r)\n",
    "\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(param):\n",
    "#     device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "#     model = CNN(param).to(device)\n",
    "#     optimizer = Adam(model.parameters(), lr=param['learning_rate'])\n",
    "#     loss_function = NLLLoss()\n",
    "#     train_data_loader, validation_data_loader = get_data(param, 'train')\n",
    "    \n",
    "\n",
    "#     for _ in range(param['epochs']):\n",
    "#         model.train()\n",
    "#         totalTrainLoss = 0\n",
    "#         totalValLoss = 0\n",
    "#         trainCorrect = 0\n",
    "#         valCorrect = 0\n",
    "#         train_counter=0\n",
    "#         validation_counter=0\n",
    "#         for (image, label) in train_data_loader:\n",
    "#             (image, label) = (image.to(device), label.to(device))\n",
    "#             prediction = model(image)\n",
    "#             loss = loss_function(prediction, label)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             totalTrainLoss += loss\n",
    "#             trainCorrect += (prediction.argmax(1) == label).type(float).sum().item()\n",
    "#             train_counter+=1\n",
    "#             print(train_counter)\n",
    "        \n",
    "#         with no_grad():\n",
    "#             model.eval()\n",
    "#             for (image, label) in validation_data_loader:\n",
    "#                 (image, label) = (image.to(device), label.to(device))\n",
    "#                 pred = model(image)\n",
    "#                 totalValLoss += loss_function(pred, label)\n",
    "#                 valCorrect += (pred.argmax(1) == label).type(float).sum().item()\n",
    "#                 validation_counter+=1\n",
    "\n",
    "#         print(f\"Train Loss --> {(totalTrainLoss/train_counter).cpu().detach().numpy()}\")\n",
    "#         print(f\"Train Accuracy --> {trainCorrect/len(train_data_loader.dataset)}\")\n",
    "#         print(f\"Validation Loss --> {(totalValLoss/validation_counter).cpu().detach().numpy()}\")\n",
    "#         print(f\"Validation Accuracy --> {valCorrect/len(validation_data_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for wandb sweeps\n",
    "def train():\n",
    "    wandb.init()\n",
    "    param = wandb.config\n",
    "    wandb.run.name = f'fltr_{param.filters}_fltrOrg_{param.filter_org}_dataAug_{param.data_augmentation}_batchNorm_{param.batch_normalization}_act_{param.activation}_batchSz_{param.batch_size}'\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = CNN(param).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=param['learning_rate'])\n",
    "    loss_function = NLLLoss()\n",
    "    train_data_loader, validation_data_loader = get_data(param, 'train')\n",
    "    \n",
    "\n",
    "    for epo in range(param['epochs']):\n",
    "        model.train()\n",
    "        totalTrainLoss = 0\n",
    "        totalValLoss = 0\n",
    "        trainCorrect = 0\n",
    "        valCorrect = 0\n",
    "        train_counter=0\n",
    "        validation_counter=0\n",
    "        for (image, label) in train_data_loader:\n",
    "            (image, label) = (image.to(device), label.to(device))\n",
    "            prediction = model(image)\n",
    "            loss = loss_function(prediction, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            totalTrainLoss += loss\n",
    "            trainCorrect += (prediction.argmax(1) == label).type(float).sum().item()\n",
    "            train_counter+=1\n",
    "            print(train_counter)\n",
    "        \n",
    "        with no_grad():\n",
    "            model.eval()\n",
    "            for (image, label) in validation_data_loader:\n",
    "                (image, label) = (image.to(device), label.to(device))\n",
    "                pred = model(image)\n",
    "                totalValLoss += loss_function(pred, label)\n",
    "                valCorrect += (pred.argmax(1) == label).type(float).sum().item()\n",
    "                validation_counter+=1\n",
    "\n",
    "        tr_ls = (totalTrainLoss/train_counter).cpu().detach().numpy()\n",
    "        tr_acc = trainCorrect/len(train_data_loader.dataset)\n",
    "        val_ls = (totalValLoss/validation_counter).cpu().detach().numpy()\n",
    "        val_acc = valCorrect/len(validation_data_loader.dataset)\n",
    "        print(f\"Train Loss --> {tr_ls}\")\n",
    "        print(f\"Train Accuracy --> {tr_acc}\")\n",
    "        print(f\"Validation Loss --> {val_ls}\")\n",
    "        print(f\"Validation Accuracy --> {val_acc}\")\n",
    "        \n",
    "        lg={\n",
    "            'epoch': epo+1,\n",
    "            'tr_accuracy': tr_acc,\n",
    "            'val_accuracy': val_acc,\n",
    "            'tr_loss': tr_ls,\n",
    "            'val_loss': val_ls\n",
    "        }\n",
    "        wandb.log(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"method\": \"grid\",  # Use grid search for this example\n",
    "  \"name\": \"Q1 Sweep\",\n",
    "  \"metric\": {\"goal\": \"maximize\", \"name\": \"val_accuracy\"},\n",
    "  \"parameters\": {\n",
    "    \"data_augmentation\":{\"values\": [True]},  # List of boolean values\n",
    "    \"batch_normalization\":{\"values\": [True]},  # List of boolean values\n",
    "    \"filters\":{\"values\": [64]},  # List of filter values for first layer\n",
    "    \"filter_org\":{\"values\": [\"half\"]},  # List of filter organization options.. , \"half\", \"double\"\n",
    "    \"dropout\":{\"values\": [0.2]},  # Dropout rates\n",
    "    \"activation\":{\"values\": [\"relu\"]},  # Activation functions... , \"tanh\", \"leaky_relu\"\n",
    "    \"batch_size\":{\"values\": [32]},\n",
    "    \"learning_rate\":{\"values\": [0.001]},\n",
    "    \"epochs\":{\"values\": [30]},\n",
    "    \"dim\":{\"values\": [256]},\n",
    "    \"conv_kernel_size\":{\"values\": [3]},\n",
    "    \"dense_neurons\":{\"values\": [1000]},\n",
    "    \"train_data_dir\":{\"values\": [\"./data/train\"]},\n",
    "    \"test_data_dir\":{\"values\": [\"./data/val\"]}\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: qx1ojawo\n",
      "Sweep URL: https://wandb.ai/cs23m070/cs6910_assignment2/sweeps/qx1ojawo\n"
     ]
    }
   ],
   "source": [
    "# wandb.init()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"cs6910_assignment2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: orxn4u44 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: half\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_data_dir: ./data/val\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_data_dir: ./data/train\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tirth/Documents/SEM2/DL/assignment/A2/code/cs6910_assignment2/wandb/run-20240401_155347-orxn4u44</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs23m070/cs6910_assignment2/runs/orxn4u44' target=\"_blank\">autumn-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m070/cs6910_assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m070/cs6910_assignment2/sweeps/qx1ojawo' target=\"_blank\">https://wandb.ai/cs23m070/cs6910_assignment2/sweeps/qx1ojawo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs23m070/cs6910_assignment2' target=\"_blank\">https://wandb.ai/cs23m070/cs6910_assignment2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs23m070/cs6910_assignment2/sweeps/qx1ojawo' target=\"_blank\">https://wandb.ai/cs23m070/cs6910_assignment2/sweeps/qx1ojawo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs23m070/cs6910_assignment2/runs/orxn4u44' target=\"_blank\">https://wandb.ai/cs23m070/cs6910_assignment2/runs/orxn4u44</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-1</strong> at: <a href='https://wandb.ai/cs23m070/cs6910_assignment2/runs/orxn4u44' target=\"_blank\">https://wandb.ai/cs23m070/cs6910_assignment2/runs/orxn4u44</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_155347-orxn4u44/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run orxn4u44 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tirth/anaconda3/envs/dl/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/6f/x1kv14zj6zqb4mjy03x74_m80000gn/T/ipykernel_3369/1974564463.py\", line 8, in train\n",
      "    model = CNN(param).to(device)\n",
      "  File \"/var/folders/6f/x1kv14zj6zqb4mjy03x74_m80000gn/T/ipykernel_3369/3062135838.py\", line 7, in __init__\n",
      "    self.act = self.getActivation(param['activation'])\n",
      "TypeError: CNN.getActivation() takes 1 positional argument but 2 were given\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run orxn4u44 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/tirth/anaconda3/envs/dl/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/6f/x1kv14zj6zqb4mjy03x74_m80000gn/T/ipykernel_3369/1974564463.py\", line 8, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = CNN(param).to(device)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/6f/x1kv14zj6zqb4mjy03x74_m80000gn/T/ipykernel_3369/3062135838.py\", line 7, in __init__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.act = self.getActivation(param['activation'])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: CNN.getActivation() takes 1 positional argument but 2 were given\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train, count=1)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print (x)\n",
    "# else:\n",
    "#     print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
