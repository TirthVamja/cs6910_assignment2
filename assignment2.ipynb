{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, ReLU, Conv2d, Linear, MaxPool2d, LogSoftmax, NLLLoss\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import flatten, float, no_grad\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {\n",
    "    'data_augmentation': False,\n",
    "    'batch_normalization': False,\n",
    "    'filters': 32, # no. of filters in first layer\n",
    "    'filter_org': 'same', # 'half', 'double'\n",
    "    'dropout': 0,\n",
    "    'activation': 'relu',\n",
    "    'train_data_dir': \"./data/train\",\n",
    "    'test_data_dir': \"./data/val\",\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    0:'Amphibia',\n",
    "    1:'Animalia',\n",
    "    2:'Arachnida',\n",
    "    3:'Aves',\n",
    "    4:'Fungi',\n",
    "    5:'Insecta',\n",
    "    6:'Mammalia',\n",
    "    7:'Mollusca',\n",
    "    8:'Plantae',\n",
    "    9:'Reptilia'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(param, type):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  # Normalize pixel values\n",
    "    ])\n",
    "\n",
    "    if(type=='train'):\n",
    "        tdataset = datasets.ImageFolder(root=param['train_data_dir'], transform=transform)\n",
    "        total = len(tdataset)\n",
    "        train_sample = math.ceil(total*(0.8))\n",
    "        val_sample = total-train_sample\n",
    "        # print(total, train_sample, val_sample)\n",
    "        train_dataset, validation_dataset = torch.utils.data.random_split(tdataset, [train_sample, val_sample])\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=param['batch_size'], shuffle=True)\n",
    "        validation_dataloader = DataLoader(validation_dataset, batch_size=param['batch_size'], shuffle=False)\n",
    "        return train_dataloader, validation_dataloader\n",
    "    \n",
    "    # for images, labels in dataloader:\n",
    "    #     # process_image_batch(images)\n",
    "    #     # process_label_batch(labels)\n",
    "  \n",
    "    #     print(f\"Image batch shape: {images.shape}\")\n",
    "    #     print(f\"Sample label: {labels}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_data(PARAMETERS, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_labels(PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(Module):\n",
    "#     def __self__(self, param):\n",
    "#         self.data_augmentation = param['data_augmentation']\n",
    "#         self.batch_normalization = param['batch_normalization']\n",
    "#         self.filters = param['filters']\n",
    "#         self.filter_org = param['filter_org']\n",
    "#         self.dropout = param['dropout']\n",
    "#         self.activation = param['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self, param):\n",
    "        super(CNN, self).__init__()\n",
    "        self.param=param\n",
    "        self.data_augmentation = param['data_augmentation']\n",
    "        self.batch_normalization = param['batch_normalization']\n",
    "        self.dropout = param['dropout']\n",
    "        self.activation = param['activation']\n",
    "        self.filters = self.filter_logic(param['filters'], param['filter_org'])\n",
    "\n",
    "        self.conv1 = Conv2d(kernel_size=(3,3), in_channels=3, out_channels=self.filters[0])\n",
    "        self.act1 = ReLU()\n",
    "        self.pool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv2 = Conv2d(kernel_size=(3,3), in_channels=self.filters[0], out_channels=self.filters[1])\n",
    "        self.act2 = ReLU()\n",
    "        self.pool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv3 = Conv2d(kernel_size=(3,3), in_channels=self.filters[1], out_channels=self.filters[2])\n",
    "        self.act3 = ReLU()\n",
    "        self.pool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv4 = Conv2d(kernel_size=(3,3), in_channels=self.filters[2], out_channels=self.filters[3])\n",
    "        self.act4 = ReLU()\n",
    "        self.pool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv5 = Conv2d(kernel_size=(3,3), in_channels=self.filters[3], out_channels=self.filters[4])\n",
    "        self.act5 = ReLU()\n",
    "        self.pool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.fc1 = Linear(in_features=1152, out_features=500)  # How to calculate dimension of filters at previous level\n",
    "        self.act6 = ReLU()\n",
    "        \n",
    "        self.out = Linear(in_features=500, out_features=10)\n",
    "        self.act7 = LogSoftmax(dim=1)\n",
    "\n",
    "    \n",
    "    def filter_logic(self, filter, org):\n",
    "        level = []\n",
    "        org = org.lower()\n",
    "        if org == 'same':\n",
    "            level = [filter for i in range(5)]\n",
    "        elif org == 'double':\n",
    "            level = [filter*pow(2,i) for i in range(5)]\n",
    "        elif org == 'half':\n",
    "            level = [max(filter//pow(2,i),1) for i in range(5)]\n",
    "        return level\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, r):\n",
    "\n",
    "        r=self.conv1(r)\n",
    "        r=self.act1(r)\n",
    "        r=self.pool1(r)\n",
    "\n",
    "        r=self.conv2(r)\n",
    "        r=self.act2(r)\n",
    "        r=self.pool2(r)\n",
    "\n",
    "        r=self.conv3(r)\n",
    "        r=self.act3(r)\n",
    "        r=self.pool3(r)\n",
    "\n",
    "        r=self.conv4(r)\n",
    "        r=self.act4(r)\n",
    "        r=self.pool4(r)\n",
    "\n",
    "        r=self.conv5(r)\n",
    "        r=self.act5(r)\n",
    "        r=self.pool5(r)\n",
    "\n",
    "        r=flatten(r,1)\n",
    "        r=self.fc1(r)\n",
    "        r=self.act6(r)\n",
    "        \n",
    "        r=self.out(r)\n",
    "        output=self.act7(r)\n",
    "\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(param):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = CNN(param).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=param['learning_rate'])\n",
    "    loss_function = NLLLoss()\n",
    "    train_data_loader, validation_data_loader = get_data(param, 'train')\n",
    "    \n",
    "\n",
    "    for _ in range(param['epochs']):\n",
    "        model.train()\n",
    "        totalTrainLoss = 0\n",
    "        totalValLoss = 0\n",
    "        trainCorrect = 0\n",
    "        valCorrect = 0\n",
    "        train_counter=0\n",
    "        validation_counter=0\n",
    "        for (image, label) in train_data_loader:\n",
    "            (image, label) = (image.to(device), label.to(device))\n",
    "            prediction = model(image)\n",
    "            loss = loss_function(prediction, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            totalTrainLoss += loss\n",
    "            trainCorrect += (prediction.argmax(1) == label).type(float).sum().item()\n",
    "            train_counter+=1\n",
    "            print(train_counter)\n",
    "        \n",
    "        with no_grad():\n",
    "            model.eval()\n",
    "            for (image, label) in validation_data_loader:\n",
    "                (image, label) = (image.to(device), label.to(device))\n",
    "                pred = model(image)\n",
    "                totalValLoss += loss_function(pred, label)\n",
    "                valCorrect += (pred.argmax(1) == label).type(float).sum().item()\n",
    "                validation_counter+=1\n",
    "\n",
    "        print(f\"Train Loss --> {(totalTrainLoss/train_counter).cpu().detach().numpy()}\")\n",
    "        print(f\"Train Accuracy --> {trainCorrect/len(train_data_loader.dataset)}\")\n",
    "        print(f\"Validation Loss --> {(totalValLoss/validation_counter).cpu().detach().numpy()}\")\n",
    "        print(f\"Validation Accuracy --> {valCorrect/len(validation_data_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "Train Loss --> 2.249912977218628\n",
      "Train Accuracy --> 0.1575\n",
      "Validation Loss --> 2.138025999069214\n",
      "Validation Accuracy --> 0.22511255627813906\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "Train Loss --> 2.111701488494873\n",
      "Train Accuracy --> 0.228\n",
      "Validation Loss --> 2.067396640777588\n",
      "Validation Accuracy --> 0.2526263131565783\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "Train Loss --> 2.020045757293701\n",
      "Train Accuracy --> 0.266625\n",
      "Validation Loss --> 1.9812588691711426\n",
      "Validation Accuracy --> 0.2801400700350175\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "Train Loss --> 1.9468566179275513\n",
      "Train Accuracy --> 0.295125\n",
      "Validation Loss --> 1.956780195236206\n",
      "Validation Accuracy --> 0.3051525762881441\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "Train Loss --> 1.8753937482833862\n",
      "Train Accuracy --> 0.33225\n",
      "Validation Loss --> 1.9247682094573975\n",
      "Validation Accuracy --> 0.31015507753876936\n"
     ]
    }
   ],
   "source": [
    "train(PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cpu')\n",
    "x = torch.rand((10000, 10000), dtype=torch.float32)\n",
    "y = torch.rand((10000, 10000), dtype=torch.float32)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1671, 0.0814, 0.5191,  ..., 0.1009, 0.0496, 0.1565],\n",
       "        [0.2021, 0.0217, 0.2716,  ..., 0.5076, 0.1028, 0.0096],\n",
       "        [0.6073, 0.1330, 0.1228,  ..., 0.6713, 0.2176, 0.0494],\n",
       "        ...,\n",
       "        [0.5357, 0.6622, 0.2862,  ..., 0.0181, 0.4730, 0.3859],\n",
       "        [0.7609, 0.3169, 0.6223,  ..., 0.2039, 0.1028, 0.6419],\n",
       "        [0.0249, 0.0267, 0.0817,  ..., 0.5312, 0.1486, 0.2523]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('mps')\n",
    "x = torch.rand((10000, 10000), dtype=torch.float32)\n",
    "y = torch.rand((10000, 10000), dtype=torch.float32)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3178e-01, 8.3787e-02, 4.4314e-01,  ..., 8.8996e-01, 1.4081e-02,\n",
       "         5.4194e-01],\n",
       "        [1.3943e-01, 1.5948e-03, 3.1647e-01,  ..., 7.4134e-01, 1.0782e-01,\n",
       "         7.6612e-02],\n",
       "        [4.8358e-01, 1.2294e-01, 5.9519e-03,  ..., 1.8317e-01, 2.0040e-02,\n",
       "         3.5919e-02],\n",
       "        ...,\n",
       "        [2.0239e-01, 5.0098e-02, 7.8769e-02,  ..., 1.7920e-02, 8.6077e-04,\n",
       "         8.5803e-03],\n",
       "        [3.4244e-01, 1.9598e-01, 1.9167e-01,  ..., 2.6779e-01, 1.8545e-01,\n",
       "         4.4428e-01],\n",
       "        [6.3024e-02, 2.0180e-01, 7.0728e-01,  ..., 1.2550e-02, 1.4994e-01,\n",
       "         7.1662e-02]], device='mps:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
